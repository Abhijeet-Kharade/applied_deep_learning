{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianmuellerklein/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/florianmuellerklein/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30000\n",
    "lstm_size = 128\n",
    "embed_size = 16\n",
    "max_word_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8124 words\n",
      "sandwich\n"
     ]
    }
   ],
   "source": [
    "with open('words/google-10000-english-usa-no-swears.txt', 'r') as word_file:\n",
    "    words = word_file.read().split('\\n')\n",
    "    \n",
    "# do a little bit of cleaning just in case\n",
    "def only_letters(some_string):\n",
    "    return ''.join([c for c in some_string if c in string.ascii_letters])\n",
    "\n",
    "def pad_front(some_word):\n",
    "    while len(some_word) < max_word_length:\n",
    "        some_word = '_' + some_word\n",
    "        \n",
    "    return some_word\n",
    "\n",
    "def pad_rear(some_word):\n",
    "    while len(some_word) < max_word_length:\n",
    "        some_word += '_'\n",
    "        \n",
    "    return some_word\n",
    "\n",
    "words = [only_letters(wrd) for wrd in words if 2 < len(wrd) < 10]\n",
    "    \n",
    "print('Found {} words'.format(len(words)))\n",
    "print(words[7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____cameras >amerascay__\n",
      "cameras ('_____cameras', '>amerascay__')\n"
     ]
    }
   ],
   "source": [
    "# create program to generate pig latin\n",
    "def make_piglatin(some_word):    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    ay = 'ay'\n",
    "\n",
    "    if some_word[0] in vowels:\n",
    "        new_word = '>' + some_word + ay\n",
    "    else:\n",
    "        new_word = '>' + some_word[1:] + some_word[0] + ay\n",
    "        \n",
    "    new_word = pad_rear(new_word)\n",
    "    old_word = pad_front(some_word)\n",
    "        \n",
    "    return old_word, new_word\n",
    "\n",
    "# test it\n",
    "old_word, new_word = make_piglatin(words[-7000])\n",
    "print(old_word, new_word)\n",
    "print(words[-7000], make_piglatin(words[-7000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get dictionaries so we can convert from letters to index and index to letters\n",
    "chars = string.ascii_letters + '>_'\n",
    "\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the place holders for our computational graph\n",
    "inputs = tf.placeholder(shape=[1, None], dtype=tf.int32, name='encoder_input')\n",
    "decoder_inputs = tf.placeholder(shape=[None, None], dtype=tf.int32, name='decoder_input')\n",
    "targets = tf.placeholder(shape=[None, vocab_size], dtype=tf.int32, name='targets')\n",
    "\n",
    "# create an initializer to init our weight matricies\n",
    "init = tf.random_normal_initializer(stddev=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the embedding layer\n",
    "embeddings = tf.get_variable(\"embeddings\", [vocab_size, embed_size], initializer=init)\n",
    "\n",
    "with tf.device('/cpu:0'), tf.name_scope(\"input_embedding\"):\n",
    "    encoder_embedding = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "\n",
    "with tf.device('/cpu:0'), tf.name_scope(\"output_embedding\"):\n",
    "    decoder_embedding = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create the encoder LSTM\n",
    "with tf.variable_scope('encoder') as enc_scope:\n",
    "    lstm_encoder = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_size),\n",
    "                                                 output_keep_prob=0.65)\n",
    "    \n",
    "    _, encoder_last_state = tf.nn.dynamic_rnn(lstm_encoder,\n",
    "                                                   inputs=encoder_embedding, \n",
    "                                                   dtype=tf.float32, \n",
    "                                                   time_major=False)\n",
    "    \n",
    "# switch to our inference helper\n",
    "inference_helper = seq2seq.GreedyEmbeddingHelper(embeddings,\n",
    "                                                 start_tokens=[char2idx['>']],\n",
    "                                                 end_token=char2idx['_'])\n",
    "\n",
    "train_helper = seq2seq.TrainingHelper(inputs=decoder_embedding, sequence_length=[11],\n",
    "                                      time_major=False)\n",
    "\n",
    "def decode(helper, scope_name, reuse=None):\n",
    "    with tf.variable_scope(scope_name, reuse=reuse) as dec_scope:\n",
    "        projection_layer = tf.layers.Dense(vocab_size, use_bias=False, name='Projection')\n",
    "        lstm_decoder = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_size),\n",
    "                                                 output_keep_prob=0.65)\n",
    "\n",
    "        decoder = seq2seq.BasicDecoder(lstm_decoder, helper, encoder_last_state, \n",
    "                                       output_layer=projection_layer)\n",
    "        outputs, _, _ = seq2seq.dynamic_decode(decoder, output_time_major=False,\n",
    "                                               impute_finished=True, maximum_iterations=20)\n",
    "\n",
    "        # get the output from the decoder\n",
    "        logits = outputs.rnn_output\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "train_logits = decode(train_helper, 'decoder')\n",
    "predictions = tf.argmax(decode(inference_helper, 'decoder', reuse=True), -1, name='decoder_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-1a8628ab6542>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=train_logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, None, 54]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logits.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.990586996078491\n",
      "Given: ______parade, Predicted: eeecceeceDe\n",
      "Given: ________goal, Predicted: >ovoacczzzH\n",
      "Given: ______jaguar, Predicted: emev_cvceev\n",
      "Given: ______meetup, Predicted: DHDDlDePwdH\n",
      "Given: ________eyed, Predicted: DeDDaPLeGH_\n",
      "Given: _______about, Predicted: meP__oowwB_\n",
      "Given: _________guy, Predicted: DovebeDDDHj\n",
      "Given: _______maine, Predicted: eerLPPeeG_l\n",
      "Given: ______matrix, Predicted: orvvccGcceG\n",
      "Given: ____cylinder, Predicted: Leeeckccccc\n",
      "\n",
      "epoch: 1000, loss: 1.6840102672576904\n",
      "Given: ______parade, Predicted: aneneaay___\n",
      "Given: ________goal, Predicted: anyaay_____\n",
      "Given: ______jaguar, Predicted: aneeraay___\n",
      "Given: ______meetup, Predicted: eneeeaay___\n",
      "Given: ________eyed, Predicted: eleaay_____\n",
      "Given: _______about, Predicted: aneeday____\n",
      "Given: _________guy, Predicted: ot_ay______\n",
      "Given: _______maine, Predicted: enlssay____\n",
      "Given: ______matrix, Predicted: aneeaaay___\n",
      "Given: ____cylinder, Predicted: oeeeeedaay_\n",
      "\n",
      "epoch: 2000, loss: 1.8633555173873901\n",
      "Given: ______parade, Predicted: ararsday___\n",
      "Given: ________goal, Predicted: aassay_____\n",
      "Given: ______jaguar, Predicted: anaadsay___\n",
      "Given: ______meetup, Predicted: ernessay___\n",
      "Given: ________eyed, Predicted: erssay_____\n",
      "Given: _______about, Predicted: antssay____\n",
      "Given: _________guy, Predicted: oscay______\n",
      "Given: _______maine, Predicted: arsssay____\n",
      "Given: ______matrix, Predicted: ariessay___\n",
      "Given: ____cylinder, Predicted: ooirnesaay_\n",
      "\n",
      "epoch: 3000, loss: 1.6800193786621094\n",
      "Given: ______parade, Predicted: atelesay___\n",
      "Given: ________goal, Predicted: eaytay_____\n",
      "Given: ______jaguar, Predicted: atealsay___\n",
      "Given: ______meetup, Predicted: ertinsay___\n",
      "Given: ________eyed, Predicted: enesay_____\n",
      "Given: _______about, Predicted: aninday____\n",
      "Given: _________guy, Predicted: itsay______\n",
      "Given: _______maine, Predicted: alnesay____\n",
      "Given: ______matrix, Predicted: ariintay___\n",
      "Given: ____cylinder, Predicted: oiiniesaay_\n",
      "\n",
      "epoch: 4000, loss: 0.8041221499443054\n",
      "Given: ______parade, Predicted: araleray___\n",
      "Given: ________goal, Predicted: oalday_____\n",
      "Given: ______jaguar, Predicted: anaalsay___\n",
      "Given: ______meetup, Predicted: eederday___\n",
      "Given: ________eyed, Predicted: eeeday_____\n",
      "Given: _______about, Predicted: aninday____\n",
      "Given: _________guy, Predicted: onsay______\n",
      "Given: _______maine, Predicted: aineray____\n",
      "Given: ______matrix, Predicted: ariinsay___\n",
      "Given: ____cylinder, Predicted: riinteraay_\n",
      "\n",
      "epoch: 5000, loss: 1.0309158563613892\n",
      "Given: ______parade, Predicted: araleray___\n",
      "Given: ________goal, Predicted: oalday_____\n",
      "Given: ______jaguar, Predicted: ataaraay___\n",
      "Given: ______meetup, Predicted: eerirray___\n",
      "Given: ________eyed, Predicted: eeeday_____\n",
      "Given: _______about, Predicted: aioiray____\n",
      "Given: _________guy, Predicted: oysay______\n",
      "Given: _______maine, Predicted: aineray____\n",
      "Given: ______matrix, Predicted: ariinlay___\n",
      "Given: ____cylinder, Predicted: riingedaay_\n",
      "\n",
      "epoch: 6000, loss: 0.6069411635398865\n",
      "Given: ______parade, Predicted: araneday___\n",
      "Given: ________goal, Predicted: oalcay_____\n",
      "Given: ______jaguar, Predicted: aruadaay___\n",
      "Given: ______meetup, Predicted: eerorray___\n",
      "Given: ________eyed, Predicted: eeeday_____\n",
      "Given: _______about, Predicted: euooday____\n",
      "Given: _________guy, Predicted: uysay______\n",
      "Given: _______maine, Predicted: aineday____\n",
      "Given: ______matrix, Predicted: ariilmay___\n",
      "Given: ____cylinder, Predicted: rrineercay_\n",
      "\n",
      "epoch: 7000, loss: 1.0521830320358276\n",
      "Given: ______parade, Predicted: aaaseday___\n",
      "Given: ________goal, Predicted: oaltay_____\n",
      "Given: ______jaguar, Predicted: ataalbay___\n",
      "Given: ______meetup, Predicted: euuurlay___\n",
      "Given: ________eyed, Predicted: eeeday_____\n",
      "Given: _______about, Predicted: aoootfy____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: aineday____\n",
      "Given: ______matrix, Predicted: arriccay___\n",
      "Given: ____cylinder, Predicted: hpictercay_\n",
      "\n",
      "epoch: 8000, loss: 0.524589478969574\n",
      "Given: ______parade, Predicted: aredebay___\n",
      "Given: ________goal, Predicted: oalyay_____\n",
      "Given: ______jaguar, Predicted: auuarbay___\n",
      "Given: ______meetup, Predicted: eepolfay___\n",
      "Given: ________eyed, Predicted: eueday_____\n",
      "Given: _______about, Predicted: aooucay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainebay____\n",
      "Given: ______matrix, Predicted: arritfay___\n",
      "Given: ____cylinder, Predicted: hlileerfay_\n",
      "\n",
      "epoch: 9000, loss: 1.3993549346923828\n",
      "Given: ______parade, Predicted: aradeaay___\n",
      "Given: ________goal, Predicted: oalkay_____\n",
      "Given: ______jaguar, Predicted: aaaalcay___\n",
      "Given: ______meetup, Predicted: eetolpay___\n",
      "Given: ________eyed, Predicted: eeeday_____\n",
      "Given: _______about, Predicted: alootay____\n",
      "Given: _________guy, Predicted: uysay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atriccay___\n",
      "Given: ____cylinder, Predicted: hiindercay_\n",
      "\n",
      "epoch: 10000, loss: 0.362505167722702\n",
      "Given: ______parade, Predicted: aradecay___\n",
      "Given: ________goal, Predicted: oalpay_____\n",
      "Given: ______jaguar, Predicted: agualaay___\n",
      "Given: ______meetup, Predicted: eetombay___\n",
      "Given: ________eyed, Predicted: eeeday_____\n",
      "Given: _______about, Predicted: aloucay____\n",
      "Given: _________guy, Predicted: uysay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atriccay___\n",
      "Given: ____cylinder, Predicted: yiindescay_\n",
      "\n",
      "epoch: 11000, loss: 0.11711576581001282\n",
      "Given: ______parade, Predicted: aradecay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aduarjay___\n",
      "Given: ______meetup, Predicted: eetommay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: atoutay____\n",
      "Given: _________guy, Predicted: yygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: yiinnercay_\n",
      "\n",
      "epoch: 12000, loss: 0.23343363404273987\n",
      "Given: ______parade, Predicted: aredepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: ayuarpay___\n",
      "Given: ______meetup, Predicted: eutommay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: auoutpy____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: ylineercay_\n",
      "\n",
      "epoch: 13000, loss: 0.17394563555717468\n",
      "Given: ______parade, Predicted: aradeaay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: agaarqay___\n",
      "Given: ______meetup, Predicted: eltommay___\n",
      "Given: ________eyed, Predicted: egeday_____\n",
      "Given: _______about, Predicted: aloutay____\n",
      "Given: _________guy, Predicted: uggay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: arrimmay___\n",
      "Given: ____cylinder, Predicted: hiiniercay_\n",
      "\n",
      "epoch: 14000, loss: 0.05422010272741318\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: yiineescay_\n",
      "\n",
      "epoch: 15000, loss: 0.29332053661346436\n",
      "Given: ______parade, Predicted: aredepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguaryay___\n",
      "Given: ______meetup, Predicted: eetommay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: yygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: hiindescay_\n",
      "\n",
      "epoch: 16000, loss: 0.008076868019998074\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: ededay_____\n",
      "Given: _______about, Predicted: abuutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: amrimmay___\n",
      "Given: ____cylinder, Predicted: hlindercay_\n",
      "\n",
      "epoch: 17000, loss: 0.05793989822268486\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: hiineercay_\n",
      "\n",
      "epoch: 18000, loss: 0.058465734124183655\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: llineercay_\n",
      "\n",
      "epoch: 19000, loss: 0.5248706340789795\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguaryay___\n",
      "Given: ______meetup, Predicted: eetucmay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: uiineescay_\n",
      "\n",
      "epoch: 20000, loss: 0.02924940548837185\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eutummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: abuutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: ylideercay_\n",
      "\n",
      "epoch: 21000, loss: 0.23177264630794525\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aqoutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: hiindescay_\n",
      "\n",
      "epoch: 22000, loss: 0.05413422733545303\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguaryay___\n",
      "Given: ______meetup, Predicted: eetupmay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: amrimmay___\n",
      "Given: ____cylinder, Predicted: ylineercay_\n",
      "\n",
      "epoch: 23000, loss: 0.004386517684906721\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eydday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrimmay___\n",
      "Given: ____cylinder, Predicted: ylindercay_\n",
      "\n",
      "epoch: 24000, loss: 0.07516086101531982\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetupmay___\n",
      "Given: ________eyed, Predicted: ekeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrinmay___\n",
      "Given: ____cylinder, Predicted: ulinrercay_\n",
      "\n",
      "epoch: 25000, loss: 0.02871869131922722\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eutummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aqoutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrinmay___\n",
      "Given: ____cylinder, Predicted: yiineercay_\n",
      "\n",
      "epoch: 26000, loss: 0.08002077788114548\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eutupmay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrinmay___\n",
      "Given: ____cylinder, Predicted: ylineercay_\n",
      "\n",
      "epoch: 27000, loss: 0.012010425329208374\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetopmay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: alrixmay___\n",
      "Given: ____cylinder, Predicted: yiindercay_\n",
      "\n",
      "epoch: 28000, loss: 0.051414672285318375\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrinmay___\n",
      "Given: ____cylinder, Predicted: hlindercay_\n",
      "\n",
      "epoch: 29000, loss: 0.018893085420131683\n",
      "Given: ______parade, Predicted: aradepay___\n",
      "Given: ________goal, Predicted: oalgay_____\n",
      "Given: ______jaguar, Predicted: aguarjay___\n",
      "Given: ______meetup, Predicted: eetummay___\n",
      "Given: ________eyed, Predicted: eyeday_____\n",
      "Given: _______about, Predicted: aboutay____\n",
      "Given: _________guy, Predicted: uygay______\n",
      "Given: _______maine, Predicted: ainemay____\n",
      "Given: ______matrix, Predicted: atrixmay___\n",
      "Given: ____cylinder, Predicted: hlindercay_\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Inference mode\n",
      "-------------------------------------\n",
      "Given: parade, Predicted: arpeaday_\n",
      "Given: goal, Predicted: oalgay_\n",
      "Given: jaguar, Predicted: aguarcay_\n",
      "Given: meetup, Predicted: emeutcay_\n",
      "Given: eyed, Predicted: eyedejay_\n",
      "Given: about, Predicted: aboutaay_\n",
      "Given: guy, Predicted: ugeypay_\n",
      "Given: maine, Predicted: mainemay_\n",
      "Given: matrix, Predicted: ymarticay_\n",
      "Given: cylinder, Predicted: ytivendapay_\n",
      "\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# get test words\n",
    "words = shuffle(words)\n",
    "test_words = words[:10]\n",
    "words = words[10:]\n",
    "\n",
    "def one_hot(v):\n",
    "    return np.eye(vocab_size)[v]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epochs):\n",
    "        rng_idx = np.random.randint(len(words))\n",
    "\n",
    "        input_word, targ_word = make_piglatin(words[rng_idx])\n",
    "\n",
    "        input_vals = [char2idx[c] for c in input_word]\n",
    "        target_vals = [char2idx[c] for c in targ_word[1:]]\n",
    "        decoder_vals = [char2idx[c] for c in targ_word[:-1]]\n",
    "\n",
    "        target_vals = one_hot(target_vals)\n",
    "\n",
    "        input_vals = np.asarray(input_vals).reshape(1, len(input_vals))\n",
    "        decoder_vals = np.asarray(decoder_vals).reshape(1, len(decoder_vals))\n",
    "\n",
    "        _, loss_val = sess.run([optimizer, loss], \n",
    "                               feed_dict={inputs: input_vals,\n",
    "                                          decoder_inputs: decoder_vals,\n",
    "                                          targets: target_vals})\n",
    "\n",
    "\n",
    "        if e % 1000 == 0:\n",
    "            print('epoch: {}, loss: {}'.format(e, loss_val))\n",
    "            \n",
    "            for i in range(len(test_words)):\n",
    "                val_word, val_targ = make_piglatin(test_words[i])\n",
    "                val_input = [char2idx[c] for c in val_word]\n",
    "                val_dec_in = [char2idx[c] for c in val_targ[:-1]]\n",
    "                \n",
    "                val_input = np.asarray(val_input).reshape(1, len(val_input))\n",
    "                val_dec_in = np.asarray(val_dec_in).reshape(1, len(val_dec_in))\n",
    "                \n",
    "                prediction = sess.run(train_logits, feed_dict={inputs: val_input,\n",
    "                                                               decoder_inputs: val_dec_in})\n",
    "                \n",
    "                prediction = np.argmax(prediction, axis=-1)\n",
    "\n",
    "                print(\"Given: {}, Predicted: {}\".format(val_word, \n",
    "                      ''.join([idx2char[idx] for idx in prediction[0]])))\n",
    "            print()\n",
    "            \n",
    "            \n",
    "    print()\n",
    "    print('-------------------------------------')\n",
    "    print('Inference mode')\n",
    "    print('-------------------------------------')\n",
    "    for i in range(len(test_words)):\n",
    "        val_input = [char2idx[c] for c in test_words[i]]\n",
    "\n",
    "        val_input = np.asarray(val_input).reshape(1, len(val_input))\n",
    "        \n",
    "        # for the inference mode we only pass the english word to translate\n",
    "        prediction = sess.run(predictions, feed_dict={inputs: val_input})\n",
    "\n",
    "        print(\"Given: {}, Predicted: {}\".format(test_words[i], \n",
    "              ''.join([idx2char[idx] for idx in prediction[0]])))\n",
    "    print()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './saved_translator/pig_latin_encoder-decoder.ckpt')\n",
    "    \n",
    "    # will save this to create a pig latin translation application, best to use frozen graph\n",
    "    relevant_nodes = ['encoder_input', 'decoder_pred']\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        relevant_nodes # The output node names are used to select the usefull nodes\n",
    "    )\n",
    "    \n",
    "    # Finally we serialize and dump the output graph to the filesystem\n",
    "    with tf.gfile.GFile('./saved_translator/piglatin_enc-dec.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
