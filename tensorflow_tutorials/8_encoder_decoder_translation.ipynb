{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30000\n",
    "lstm_size = 1024\n",
    "embed_size = 64\n",
    "max_word_length = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8124 words\n",
      "sandwich\n"
     ]
    }
   ],
   "source": [
    "with open('words/google-10000-english-usa-no-swears.txt', 'r') as word_file:\n",
    "    words = word_file.read().split('\\n')\n",
    "    \n",
    "# do a little bit of cleaning just in case\n",
    "def only_letters(some_string):\n",
    "    return ''.join([c for c in some_string if c in string.ascii_letters])\n",
    "\n",
    "def pad_front(some_word):\n",
    "    while len(some_word) < max_word_length:\n",
    "        some_word = '_' + some_word\n",
    "        \n",
    "    return some_word\n",
    "\n",
    "def pad_rear(some_word):\n",
    "    while len(some_word) < max_word_length:\n",
    "        some_word += '_'\n",
    "        \n",
    "    return some_word\n",
    "\n",
    "words = [only_letters(wrd) for wrd in words if 2 < len(wrd) < 10]\n",
    "    \n",
    "print('Found {} words'.format(len(words)))\n",
    "print(words[7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____cameras >amerascay__\n",
      "cameras ('_____cameras', '>amerascay__')\n"
     ]
    }
   ],
   "source": [
    "# create program to generate pig latin\n",
    "def make_piglatin(some_word):    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    ay = 'ay'\n",
    "\n",
    "    if some_word[0] in vowels:\n",
    "        new_word = '>' + some_word + ay\n",
    "    else:\n",
    "        new_word = '>' + some_word[1:] + some_word[0] + ay\n",
    "        \n",
    "    new_word = pad_rear(new_word)\n",
    "    old_word = pad_front(some_word)\n",
    "        \n",
    "    return old_word, new_word\n",
    "\n",
    "# test it\n",
    "old_word, new_word = make_piglatin(words[-7000])\n",
    "print(old_word, new_word)\n",
    "print(words[-7000], make_piglatin(words[-7000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionaries so we can convert from letters to index and index to letters\n",
    "chars = string.ascii_letters + '>_'\n",
    "\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the place holders for our computational graph\n",
    "inputs = tf.placeholder(shape=[1, None], dtype=tf.int32, name='encoder_input')\n",
    "decoder_inputs = tf.placeholder(shape=[None, None], dtype=tf.int32, name='decoder_input')\n",
    "targets = tf.placeholder(shape=[None, vocab_size], dtype=tf.int32, name='targets')\n",
    "\n",
    "# create an initializer to init our weight matricies\n",
    "init = tf.random_normal_initializer(stddev=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the embedding layer\n",
    "embeddings = tf.get_variable(\"embeddings\", [vocab_size, embed_size], initializer=init)\n",
    "\n",
    "with tf.device('/cpu:0'), tf.name_scope(\"input_embedding\"):\n",
    "    encoder_embedding = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "\n",
    "with tf.device('/cpu:0'), tf.name_scope(\"output_embedding\"):\n",
    "    decoder_embedding = tf.nn.embedding_lookup(embeddings, decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the encoder LSTM\n",
    "with tf.variable_scope('encoder') as enc_scope:\n",
    "    lstm_encoder = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_size),\n",
    "                                                 output_keep_prob=0.65)\n",
    "    \n",
    "    _, encoder_last_state = tf.nn.dynamic_rnn(lstm_encoder,\n",
    "                                                   inputs=encoder_embedding, \n",
    "                                                   dtype=tf.float32, \n",
    "                                                   time_major=False)\n",
    "    \n",
    "# switch to our inference helper\n",
    "inference_helper = seq2seq.GreedyEmbeddingHelper(embeddings,\n",
    "                                                 start_tokens=[char2idx['>']],\n",
    "                                                 end_token=char2idx['_'])\n",
    "\n",
    "train_helper = seq2seq.TrainingHelper(inputs=decoder_embedding, sequence_length=[11],\n",
    "                                      time_major=False)\n",
    "\n",
    "def decode(helper, scope_name, reuse=None):\n",
    "    with tf.variable_scope(scope_name, reuse=reuse) as dec_scope:\n",
    "        projection_layer = tf.layers.Dense(vocab_size, use_bias=False, name='Projection')\n",
    "        lstm_decoder = tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(lstm_size),\n",
    "                                                 output_keep_prob=0.65)\n",
    "\n",
    "        decoder = seq2seq.BasicDecoder(lstm_decoder, helper, encoder_last_state, \n",
    "                                       output_layer=projection_layer)\n",
    "        outputs, _, _ = seq2seq.dynamic_decode(decoder, output_time_major=False,\n",
    "                                               impute_finished=True, maximum_iterations=20)\n",
    "\n",
    "        # get the output from the decoder\n",
    "        logits = outputs.rnn_output\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "train_logits = decode(train_helper, 'decoder')\n",
    "predictions = tf.argmax(decode(inference_helper, 'decoder', reuse=True), -1, name='decoder_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-1a8628ab6542>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=train_logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, None, 54]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logits.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 4.004409313201904\n",
      "Given: ___retrieved, Predicted: ___________\n",
      "Given: ______israel, Predicted: ___________\n",
      "Given: ___indicated, Predicted: ___________\n",
      "Given: ___affiliate, Predicted: ___________\n",
      "Given: _____notices, Predicted: ___________\n",
      "Given: _____propose, Predicted: ___________\n",
      "Given: ____minister, Predicted: e__________\n",
      "Given: ________guam, Predicted: ___________\n",
      "Given: ________oval, Predicted: ___________\n",
      "Given: _______crash, Predicted: ___________\n",
      "\n",
      "epoch: 1000, loss: 1.9559516906738281\n",
      "Given: ___retrieved, Predicted: artensaaaay\n",
      "Given: ______israel, Predicted: entey_ay___\n",
      "Given: ___indicated, Predicted: antenayaaay\n",
      "Given: ___affiliate, Predicted: ertanany_ay\n",
      "Given: _____notices, Predicted: artnaaaay__\n",
      "Given: _____propose, Predicted: eatenssay__\n",
      "Given: ____minister, Predicted: antnsaaaay_\n",
      "Given: ________guam, Predicted: erteay_____\n",
      "Given: ________oval, Predicted: aneyey_____\n",
      "Given: _______crash, Predicted: iattaay____\n",
      "\n",
      "epoch: 2000, loss: 2.050320863723755\n",
      "Given: ___retrieved, Predicted: oreandersay\n",
      "Given: ______israel, Predicted: onteldpy___\n",
      "Given: ___indicated, Predicted: ontentlesay\n",
      "Given: ___affiliate, Predicted: olioatnnfay\n",
      "Given: _____notices, Predicted: orenessay__\n",
      "Given: _____propose, Predicted: oanerssay__\n",
      "Given: ____minister, Predicted: ontneorsay_\n",
      "Given: ________guam, Predicted: oansay_____\n",
      "Given: ________oval, Predicted: onenay_____\n",
      "Given: _______crash, Predicted: oantsay____\n",
      "\n",
      "epoch: 3000, loss: 1.5523089170455933\n",
      "Given: ___retrieved, Predicted: eniennedtay\n",
      "Given: ______israel, Predicted: entensay___\n",
      "Given: ___indicated, Predicted: entinenesay\n",
      "Given: ___affiliate, Predicted: artininnlay\n",
      "Given: _____notices, Predicted: ertnestay__\n",
      "Given: _____propose, Predicted: eertntpay__\n",
      "Given: ____minister, Predicted: entntestay_\n",
      "Given: ________guam, Predicted: arttay_____\n",
      "Given: ________oval, Predicted: aresay_____\n",
      "Given: _______crash, Predicted: earttay____\n",
      "\n",
      "epoch: 4000, loss: 0.7473229765892029\n",
      "Given: ___retrieved, Predicted: eseessedcay\n",
      "Given: ______israel, Predicted: ishotday___\n",
      "Given: ___indicated, Predicted: ivtineneday\n",
      "Given: ___affiliate, Predicted: aciicictsay\n",
      "Given: _____notices, Predicted: oninescay__\n",
      "Given: _____propose, Predicted: rorertfay__\n",
      "Given: ____minister, Predicted: intneedlay_\n",
      "Given: ________guam, Predicted: uatsay_____\n",
      "Given: ________oval, Predicted: oaaday_____\n",
      "Given: _______crash, Predicted: hassfay____\n",
      "\n",
      "epoch: 5000, loss: 1.065584659576416\n",
      "Given: ___retrieved, Predicted: eriiesidgay\n",
      "Given: ______israel, Predicted: iraaaday___\n",
      "Given: ___indicated, Predicted: incicaleday\n",
      "Given: ___affiliate, Predicted: ampiaaeleay\n",
      "Given: _____notices, Predicted: otintssay__\n",
      "Given: _____propose, Predicted: romtrtcay__\n",
      "Given: ____minister, Predicted: indneerfay_\n",
      "Given: ________guam, Predicted: ullbay_____\n",
      "Given: ________oval, Predicted: olalay_____\n",
      "Given: _______crash, Predicted: ramthay____\n",
      "\n",
      "epoch: 6000, loss: 0.16755563020706177\n",
      "Given: ___retrieved, Predicted: errivvedray\n",
      "Given: ______israel, Predicted: isaayray___\n",
      "Given: ___indicated, Predicted: indicaleday\n",
      "Given: ___affiliate, Predicted: amlililleay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: rocosepay__\n",
      "Given: ____minister, Predicted: inittermay_\n",
      "Given: ________guam, Predicted: uambay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rattcay____\n",
      "\n",
      "epoch: 7000, loss: 0.2556454837322235\n",
      "Given: ___retrieved, Predicted: etreeeedday\n",
      "Given: ______israel, Predicted: islallay___\n",
      "Given: ___indicated, Predicted: innicateday\n",
      "Given: ___affiliate, Predicted: apfiaiaieay\n",
      "Given: _____notices, Predicted: oticedday__\n",
      "Given: _____propose, Predicted: ropoeepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: ubmhay_____\n",
      "Given: ________oval, Predicted: ovalby_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 8000, loss: 0.44811543822288513\n",
      "Given: ___retrieved, Predicted: etrieredray\n",
      "Given: ______israel, Predicted: israllay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: apiilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: rooosepay__\n",
      "Given: ____minister, Predicted: inintermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rastcay____\n",
      "\n",
      "epoch: 9000, loss: 0.09001433104276657\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israllay___\n",
      "Given: ___indicated, Predicted: indictteday\n",
      "Given: ___affiliate, Predicted: affllitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 10000, loss: 0.11637008190155029\n",
      "Given: ___retrieved, Predicted: etriewedray\n",
      "Given: ______israel, Predicted: israllay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticennay__\n",
      "Given: _____propose, Predicted: ropesepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamtay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 11000, loss: 0.05904519185423851\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affiaitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inittermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 12000, loss: 0.13779698312282562\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: isreelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affiiiateay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roppsepay__\n",
      "Given: ____minister, Predicted: indstermay_\n",
      "Given: ________guam, Predicted: uamtay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 13000, loss: 0.008399317041039467\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indineneday\n",
      "Given: ___affiliate, Predicted: affilieeeay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: insstermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 14000, loss: 0.017811639234423637\n",
      "Given: ___retrieved, Predicted: etrievedlay\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affiiinteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 15000, loss: 0.0036050251219421625\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicadeday\n",
      "Given: ___affiliate, Predicted: affilieteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: insstermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 16000, loss: 0.0028212780598551035\n",
      "Given: ___retrieved, Predicted: etreevedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 17000, loss: 0.0014262777986004949\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affizieteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 18000, loss: 0.001122013432905078\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 19000, loss: 0.0007768750656396151\n",
      "Given: ___retrieved, Predicted: etreevedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 20000, loss: 0.046427492052316666\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indiaateday\n",
      "Given: ___affiliate, Predicted: affiaitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposspay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 21000, loss: 0.009747181087732315\n",
      "Given: ___retrieved, Predicted: etrivvedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indccateday\n",
      "Given: ___affiliate, Predicted: affiaiateay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 22000, loss: 0.00658486457541585\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 23000, loss: 0.003967868164181709\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israllay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: aamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 24000, loss: 0.00014347520482260734\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: isaaelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 25000, loss: 0.002604413079097867\n",
      "Given: ___retrieved, Predicted: etrieredray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 26000, loss: 7.554134936071932e-05\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: isreelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteaa\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 27000, loss: 0.0036023729480803013\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: isreelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 28000, loss: 4.377182631287724e-05\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "epoch: 29000, loss: 0.0008668530499562621\n",
      "Given: ___retrieved, Predicted: etrievedray\n",
      "Given: ______israel, Predicted: israelay___\n",
      "Given: ___indicated, Predicted: indicateday\n",
      "Given: ___affiliate, Predicted: affilitteay\n",
      "Given: _____notices, Predicted: oticesnay__\n",
      "Given: _____propose, Predicted: roposepay__\n",
      "Given: ____minister, Predicted: inistermay_\n",
      "Given: ________guam, Predicted: uamgay_____\n",
      "Given: ________oval, Predicted: ovalay_____\n",
      "Given: _______crash, Predicted: rashcay____\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Inference mode\n",
      "-------------------------------------\n",
      "Given: retrieved, Predicted: eterviedray_\n",
      "Given: israel, Predicted: iirsealay_\n",
      "Given: indicated, Predicted: inidectidpay_\n",
      "Given: affiliate, Predicted: iafinfalteay_\n",
      "Given: notices, Predicted: oticensay_\n",
      "Given: propose, Predicted: roporsepay_\n",
      "Given: minister, Predicted: inistermay_\n",
      "Given: guam, Predicted: ugapay_\n",
      "Given: oval, Predicted: ovoalay_\n",
      "Given: crash, Predicted: racheay_\n",
      "\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# get test words\n",
    "words = shuffle(words)\n",
    "test_words = words[:10]\n",
    "words = words[10:]\n",
    "\n",
    "def one_hot(v):\n",
    "    return np.eye(vocab_size)[v]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for e in range(epochs):\n",
    "        rng_idx = np.random.randint(len(words))\n",
    "\n",
    "        input_word, targ_word = make_piglatin(words[rng_idx])\n",
    "\n",
    "        input_vals = [char2idx[c] for c in input_word]\n",
    "        target_vals = [char2idx[c] for c in targ_word[1:]]\n",
    "        decoder_vals = [char2idx[c] for c in targ_word[:-1]]\n",
    "\n",
    "        target_vals = one_hot(target_vals)\n",
    "\n",
    "        input_vals = np.asarray(input_vals).reshape(1, len(input_vals))\n",
    "        decoder_vals = np.asarray(decoder_vals).reshape(1, len(decoder_vals))\n",
    "\n",
    "        _, loss_val = sess.run([optimizer, loss], \n",
    "                               feed_dict={inputs: input_vals,\n",
    "                                          decoder_inputs: decoder_vals,\n",
    "                                          targets: target_vals})\n",
    "\n",
    "\n",
    "        if e % 1000 == 0:\n",
    "            print('epoch: {}, loss: {}'.format(e, loss_val))\n",
    "            \n",
    "            for i in range(len(test_words)):\n",
    "                val_word, val_targ = make_piglatin(test_words[i])\n",
    "                val_input = [char2idx[c] for c in val_word]\n",
    "                val_dec_in = [char2idx[c] for c in val_targ[:-1]]\n",
    "                \n",
    "                val_input = np.asarray(val_input).reshape(1, len(val_input))\n",
    "                val_dec_in = np.asarray(val_dec_in).reshape(1, len(val_dec_in))\n",
    "                \n",
    "                prediction = sess.run(train_logits, feed_dict={inputs: val_input,\n",
    "                                                               decoder_inputs: val_dec_in})\n",
    "                \n",
    "                prediction = np.argmax(prediction, axis=-1)\n",
    "\n",
    "                print(\"Given: {}, Predicted: {}\".format(val_word, \n",
    "                      ''.join([idx2char[idx] for idx in prediction[0]])))\n",
    "            print()\n",
    "            \n",
    "            \n",
    "    print()\n",
    "    print('-------------------------------------')\n",
    "    print('Inference mode')\n",
    "    print('-------------------------------------')\n",
    "    for i in range(len(test_words)):\n",
    "        val_input = [char2idx[c] for c in test_words[i]]\n",
    "\n",
    "        val_input = np.asarray(val_input).reshape(1, len(val_input))\n",
    "        \n",
    "        # for the inference mode we only pass the english word to translate\n",
    "        prediction = sess.run(predictions, feed_dict={inputs: val_input})\n",
    "\n",
    "        print(\"Given: {}, Predicted: {}\".format(test_words[i], \n",
    "              ''.join([idx2char[idx] for idx in prediction[0]])))\n",
    "    print()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, './saved_translator/pig_latin_encoder-decoder.ckpt')\n",
    "    \n",
    "    # will save this to create a pig latin translation application, best to use frozen graph\n",
    "    relevant_nodes = ['encoder_input', 'decoder_pred']\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        relevant_nodes # The output node names are used to select the usefull nodes\n",
    "    )\n",
    "    \n",
    "    # Finally we serialize and dump the output graph to the filesystem\n",
    "    with tf.gfile.GFile('./saved_translator/piglatin_enc-dec.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
