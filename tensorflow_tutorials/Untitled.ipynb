{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florian/anaconda3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_translator/pig_latin_encoder-decoder.ckpt\n",
      "Given: test, Predicted: ettesay_\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "chars = string.ascii_letters + '>_'\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# best weight values are saved in the checkpoint\n",
    "with tf.Session() as sess:\n",
    "    # restore the session that we used to train the model\n",
    "    saver = tf.train.import_meta_graph('./saved_translator/pig_latin_encoder-decoder.ckpt.meta')\n",
    "    saver.restore(sess, './saved_translator/pig_latin_encoder-decoder.ckpt')\n",
    "    \n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #for op in graph.get_operations():\n",
    "    #    if 'input' in str(op.name):\n",
    "    #        print(str(op.name))\n",
    "\n",
    "    \n",
    "    #show_graph(graph)\n",
    "    \n",
    "    word_input = graph.get_tensor_by_name('encoder_input:0')\n",
    "    predictions = graph.get_tensor_by_name('decoder_pred:0')\n",
    "    \n",
    "    val_input = [char2idx[c] for c in 'test']\n",
    "\n",
    "    val_input = np.asarray(val_input).reshape(1, len(val_input))\n",
    "\n",
    "    # for the inference mode we only pass the english word to translate\n",
    "    prediction = sess.run(predictions, feed_dict={word_input: val_input})\n",
    "\n",
    "    print(\"Given: {}, Predicted: {}\".format('test', \n",
    "          ''.join([idx2char[idx] for idx in prediction[0]])))    \n",
    "            \n",
    "    relevant_nodes = ['encoder_input', 'decoder_pred']\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        relevant_nodes # The output node names are used to select the usefull nodes\n",
    "    )\n",
    "    \n",
    "    # Finally we serialize and dump the output graph to the filesystem\n",
    "    with tf.gfile.GFile('./saved_translator/piglatin_enc-dec.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onetarytay hitesay teonay ipgliatinray lepasesay\n"
     ]
    }
   ],
   "source": [
    "test_sentence = 'Convert this to piglatin please'\n",
    "\n",
    "def load_graph(graph_flnm):\n",
    "    with tf.gfile.GFile(graph_flnm, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        \n",
    "        # the prefix will be import by default, so we'll give it something meaningful\n",
    "        tf.import_graph_def(graph_def, name='enc-dec')\n",
    "\n",
    "    return graph\n",
    "    \n",
    "graph = load_graph('./saved_translator/piglatin_enc-dec.pb')\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    word_input = graph.get_tensor_by_name('enc-dec/encoder_input:0')\n",
    "    predictions = graph.get_tensor_by_name('enc-dec/decoder_pred:0')\n",
    "    \n",
    "    output_translation = []\n",
    "    for word in test_sentence.split():\n",
    "    \n",
    "        val_input = [char2idx[c] for c in word]\n",
    "        val_input = np.asarray(val_input).reshape(1, len(val_input))\n",
    "\n",
    "        # for the inference mode we only pass the english word to translate\n",
    "        prediction = sess.run(predictions, feed_dict={word_input: val_input})\n",
    "\n",
    "         \n",
    "        output_translation.append(''.join([idx2char[idx] for idx in prediction[0]]))\n",
    "        \n",
    "print(' '.join(output_translation).replace('_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
