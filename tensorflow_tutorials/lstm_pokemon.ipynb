{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in some text to use\n",
    "poke_df = pd.read_csv('pokemon/Pokemon.csv')\n",
    "poke_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulbasaur Grass |\n"
     ]
    }
   ],
   "source": [
    "def strip_non_ascii(some_string):\n",
    "    return ''.join([c for c in some_string if c in string.printable])\n",
    "\n",
    "pokemons = [\"{} {} |\".format(df_row[1]['Name'], df_row[1]['Type 1']) for df_row in poke_df.iterrows()]\n",
    "pokemons = [strip_non_ascii(pokemon) for pokemon in pokemons]\n",
    "print(pokemons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_iter(pokemon_names):\n",
    "    inp = pokemon_names[:-1] # all but last\n",
    "    targ = pokemon_names[1:] # all but first\n",
    "    \n",
    "    return inp, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is 800 pokemon long and there are 100 unique characters.\n"
     ]
    }
   ],
   "source": [
    "# need to get all of the possible characters that the source uses\n",
    "chars = string.printable\n",
    "\n",
    "data_size, vocab_size = len(pokemons), len(chars)\n",
    "print('Text is', data_size, 'pokemon long and there are', vocab_size, 'unique characters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dictionaries to convert from characters to index and from index back to characters\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# get the char ids for each character\n",
    "char_ids = list(idx2char.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define some hyperparameters for our network\n",
    "embed_size = 64\n",
    "hidden_size = 128\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN in tensorflow\n",
    "\n",
    "In this notebook we'll work in Tensorflow directly. I would recommend getting familiar with how neural networks work by using our previous examples and then once you feel comfortable with Keras and all of the high level concepts move into Tensorflow. \n",
    "\n",
    "Tensorflow does give us a few helper functions to facilitate the construction of neural networks, but mostly we will be building lots of things from scratch. The one thing that we definitely don't want to do is calculate the backward pass for our training steps, luckily this is something that Tensorflow will do for us. \n",
    "\n",
    "In this example we will create a GRU recurrent neural network to use in our character level RNN. The steps for creating this network from scratch will be:\n",
    "\n",
    "* Initialize all of our weight matrices. Setup their sizes and fill with random numbers\n",
    "* Define the calculations that our network must carry out\n",
    "\n",
    "A GRU cell is basically a change in the way that the hidden state is calculated for a recurrent neural network. So to begin we'll start with a vanilla recurrent neural network and show how we can create one using the two steps above. \n",
    "\n",
    "### Vanilla RNN\n",
    "\n",
    "The calculations for a recurrent neural network look like the following:\n",
    "\n",
    "![rnn](images/rnn.png)\n",
    "\n",
    "In order to create that we need to set up three matrices and two bias vectors. The specify the calculations in exactly the same way. \n",
    "\n",
    "```python\n",
    "Uh = tf.get_variable(\"Uh\", [input_size, hidden_size], initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "Wh = tf.get_variable(\"Wh\", [hidden_size, hidden_size], initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "Vy = tf.get_variable(\"Vy\", [hidden_size, vocab_size], initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "bh  = tf.get_variable(\"bh\", [hidden_size], initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "by  = tf.get_variable(\"by\", [output_size], initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "\n",
    "hs_t = tf.tanh(tf.matmul(xs_t, Uh) + tf.matmul(hs_t, Wh) + bh)\n",
    "ys_t = tf.nn.softmax(tf.matmul(hs_t, Vy) + by)\n",
    "```\n",
    "\n",
    "Simple enough. Input_size and output_size will change depending on the properties of our data. Hidden_size is a hyperparameter that we can set to anything that we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the place holders for our computational graph\n",
    "inputs = tf.placeholder(shape=[None, 1], dtype=tf.int32, name='input')\n",
    "targets = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name='targets')\n",
    "init_state = tf.placeholder(shape=[1, hidden_size], dtype=tf.float32, name='state')\n",
    "\n",
    "# create an initializer to init our weight matricies\n",
    "init = tf.random_normal_initializer(stddev=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the embedding layer\n",
    "with tf.device('/cpu:0'), tf.name_scope(\"Embedding\"):\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, embed_size], initializer=init)\n",
    "    inputs_embedding = tf.nn.embedding_lookup(embedding, inputs)\n",
    "    inputs_embedding = tf.reshape(inputs_embedding, (1, embed_size))\n",
    "    \n",
    "# set up our recurrent neural network and define the functions\n",
    "with tf.variable_scope(\"RNN\") as scope:\n",
    "    # hidden state at time t \n",
    "    hs_t = init_state\n",
    "    \n",
    "    #Fh = tf.get_variable('Fh', [hidden_size, hidden_size], initializer=init)\n",
    "    #Ih = tf.get_variable('Ih', [hidden_size, hidden_size], initializer=init)\n",
    "    #Ch = tf.get_variable('Ch', [hidden_size, hidden_size], initializer=init)\n",
    "    #Oh = tf.get_variable('Oh', [hidden_size, hidden_size], initializer=init)\n",
    "\n",
    "    # weight from input to hidden for z gate\n",
    "    Uz = tf.get_variable(\"Uz\", [embed_size, hidden_size], initializer=init)\n",
    "    # weight from hidden to hidden for z gate\n",
    "    Wz = tf.get_variable(\"Wz\", [hidden_size, hidden_size], initializer=init)\n",
    "    # bias for the z gate calculation\n",
    "    bz = tf.get_variable(\"bz\", [hidden_size], initializer=init)\n",
    "\n",
    "    # weight from input to hidden for r gate\n",
    "    Ur = tf.get_variable(\"Ur\", [embed_size, hidden_size], initializer=init)\n",
    "    # weight from hidden to hidden for r gate\n",
    "    Wr = tf.get_variable(\"Wr\", [hidden_size, hidden_size], initializer=init)\n",
    "    # bias for the r gate calculation\n",
    "    br = tf.get_variable(\"br\", [hidden_size], initializer=init)\n",
    "\n",
    "    # weight from input to hidden\n",
    "    Uh = tf.get_variable(\"Uh\", [embed_size, hidden_size], initializer=init)\n",
    "\n",
    "    # recurrent weight matrix, hidden 2 hidden\n",
    "    Wh = tf.get_variable(\"Wh\", [hidden_size, hidden_size], initializer=init)\n",
    "    # bias for hidden matrix\n",
    "    bh = tf.get_variable(\"bh\", [hidden_size], initializer=init)\n",
    "\n",
    "    # output weight matrix\n",
    "    Vy = tf.get_variable(\"Vy\", [hidden_size, vocab_size], initializer=init)\n",
    "    # bias for output matrix\n",
    "    by = tf.get_variable(\"by\", [vocab_size], initializer=init)\n",
    "    \n",
    "    \n",
    "\n",
    "    # perform the z gate calculation\n",
    "    zt = tf.sigmoid(tf.matmul(inputs_embedding, Uz) + tf.matmul(hs_t, Wz) + bz)\n",
    "    # perform the r gate calculation\n",
    "    rt = tf.sigmoid(tf.matmul(inputs_embedding, Ur) + tf.matmul(hs_t, Wr) + br)\n",
    "    # perform the hidden state calculation\n",
    "    htilda_t = tf.tanh(tf.matmul(inputs_embedding, Uh) + tf.matmul(tf.multiply(rt, hs_t), Wh) + bh)\n",
    "    hs_t = tf.multiply((1 - zt), hs_t) + tf.multiply(zt, htilda_t)\n",
    "    # perform the ouput calculation\n",
    "    ys_t = tf.matmul(hs_t, Vy) + by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-395ad74c675f>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# need to keep track of our hidden states\n",
    "h_0 = hs_t\n",
    "# apply the softmax output to the last output of our list\n",
    "output_softmax = tf.nn.softmax(ys_t)\n",
    "\n",
    "# get all of the output characters together\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=ys_t))\n",
    "\n",
    "# optimization algorithm\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0003)\n",
    "grads = optimizer.compute_gradients(loss)\n",
    "\n",
    "# clip the gradients\n",
    "grad_clipping = tf.constant(5.0, name='grad_clipping')\n",
    "clipped_grads = []\n",
    "for grad, var in grads:\n",
    "    clipped_grad = tf.clip_by_value(grad, -grad_clipping, grad_clipping)\n",
    "    clipped_grads.append((clipped_grad, var))\n",
    "    \n",
    "# update the weights with gradient descent\n",
    "updates = optimizer.apply_gradients(clipped_grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, p: 0, loss: 4.543635\n",
      "----\n",
      " T,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, \n",
      "----\n",
      "\n",
      "iter: 1000, p: 0, loss: 1.842562\n",
      "----\n",
      " Fire  \n",
      "----\n",
      "\n",
      "iter: 2000, p: 0, loss: 1.514019\n",
      "----\n",
      " Ice  \n",
      "----\n",
      "\n",
      "iter: 3000, p: 0, loss: 1.608493\n",
      "----\n",
      " Water  \n",
      "----\n",
      "\n",
      "iter: 4000, p: 0, loss: 1.523741\n",
      "----\n",
      " Q \n",
      "----\n",
      "\n",
      "iter: 5000, p: 0, loss: 1.759600\n",
      "----\n",
      " Dragon  \n",
      "----\n",
      "\n",
      "iter: 6000, p: 0, loss: 1.647490\n",
      "----\n",
      " Alorita Grass  \n",
      "----\n",
      "\n",
      "iter: 7000, p: 0, loss: 1.331352\n",
      "----\n",
      " Cless Fire  \n",
      "----\n",
      "\n",
      "iter: 8000, p: 0, loss: 0.927361\n",
      "----\n",
      " Coter  \n",
      "----\n",
      "\n",
      "iter: 9000, p: 0, loss: 0.960307\n",
      "----\n",
      " Vock  \n",
      "----\n",
      "\n",
      "iter: 10000, p: 0, loss: 1.148187\n",
      "----\n",
      " Poison  \n",
      "----\n",
      "\n",
      "iter: 11000, p: 0, loss: 0.776531\n",
      "----\n",
      " Ice  \n",
      "----\n",
      "\n",
      "iter: 12000, p: 0, loss: 1.135005\n",
      "----\n",
      " Electric  \n",
      "----\n",
      "\n",
      "iter: 13000, p: 0, loss: 1.073618\n",
      "----\n",
      " Morme Grass  \n",
      "----\n",
      "\n",
      "iter: 14000, p: 0, loss: 2.026309\n",
      "----\n",
      " Rock  \n",
      "----\n",
      "\n",
      "iter: 15000, p: 0, loss: 0.694239\n",
      "----\n",
      " Ice  \n",
      "----\n",
      "\n",
      "iter: 16000, p: 0, loss: 0.719118\n",
      "----\n",
      " O \n",
      "----\n",
      "\n",
      "iter: 17000, p: 0, loss: 1.043584\n",
      "----\n",
      " Qug  \n",
      "----\n",
      "\n",
      "iter: 18000, p: 0, loss: 0.777884\n",
      "----\n",
      " T \n",
      "----\n",
      "\n",
      "iter: 19000, p: 0, loss: 0.933831\n",
      "----\n",
      " Vormanderia Dark  \n",
      "----\n",
      "\n",
      "iter: 20000, p: 0, loss: 0.904193\n",
      "----\n",
      " Pock  \n",
      "----\n",
      "\n",
      "iter: 21000, p: 0, loss: 0.851641\n",
      "----\n",
      " Steel  \n",
      "----\n",
      "\n",
      "iter: 22000, p: 0, loss: 0.723100\n",
      "----\n",
      " Kirl Psychic  \n",
      "----\n",
      "\n",
      "iter: 23000, p: 0, loss: 0.728721\n",
      "----\n",
      " Ulectric  \n",
      "----\n",
      "\n",
      "iter: 24000, p: 0, loss: 0.812912\n",
      "----\n",
      " Mocand Forme Grass  \n",
      "----\n",
      "\n",
      "iter: 25000, p: 0, loss: 0.865277\n",
      "----\n",
      " Luck  \n",
      "----\n",
      "\n",
      "iter: 26000, p: 0, loss: 1.027805\n",
      "----\n",
      " Dragon  \n",
      "----\n",
      "\n",
      "iter: 27000, p: 0, loss: 0.799655\n",
      "----\n",
      " Lerna Bug  \n",
      "----\n",
      "\n",
      "iter: 28000, p: 0, loss: 0.598894\n",
      "----\n",
      " Fire  \n",
      "----\n",
      "\n",
      "iter: 29000, p: 0, loss: 0.599786\n",
      "----\n",
      " Qotor Bug  \n",
      "----\n",
      "\n",
      "iter: 30000, p: 0, loss: 0.780997\n",
      "----\n",
      " Mitebler Gragon  \n",
      "----\n",
      "\n",
      "iter: 31000, p: 0, loss: 0.884601\n",
      "----\n",
      " Ick Normal  \n",
      "----\n",
      "\n",
      "iter: 32000, p: 0, loss: 0.364334\n",
      "----\n",
      " Psychic  \n",
      "----\n",
      "\n",
      "iter: 33000, p: 0, loss: 0.675273\n",
      "----\n",
      " A \n",
      "----\n",
      "\n",
      "iter: 34000, p: 0, loss: 0.885114\n",
      "----\n",
      " Jrass  \n",
      "----\n",
      "\n",
      "iter: 35000, p: 0, loss: 0.775302\n",
      "----\n",
      " Honectricune Water  \n",
      "----\n",
      "\n",
      "iter: 36000, p: 0, loss: 0.466925\n",
      "----\n",
      " X Ghost  \n",
      "----\n",
      "\n",
      "iter: 37000, p: 0, loss: 0.750216\n",
      "----\n",
      " Honfik  \n",
      "----\n",
      "\n",
      "iter: 38000, p: 0, loss: 0.951438\n",
      "----\n",
      " Xater  \n",
      "----\n",
      "\n",
      "iter: 39000, p: 0, loss: 0.698916\n",
      "----\n",
      " Vormal  \n",
      "----\n",
      "\n",
      "iter: 40000, p: 0, loss: 0.650712\n",
      "----\n",
      " Steel  \n",
      "----\n",
      "\n",
      "iter: 41000, p: 0, loss: 0.564293\n",
      "----\n",
      " Qug  \n",
      "----\n",
      "\n",
      "iter: 42000, p: 0, loss: 0.475627\n",
      "----\n",
      " Clerede Bug  \n",
      "----\n",
      "\n",
      "iter: 43000, p: 0, loss: 0.707194\n",
      "----\n",
      " Uloe Water  \n",
      "----\n",
      "\n",
      "iter: 44000, p: 0, loss: 0.699117\n",
      "----\n",
      " Ground  \n",
      "----\n",
      "\n",
      "iter: 45000, p: 0, loss: 0.932218\n",
      "----\n",
      " Yyte Grass  \n",
      "----\n",
      "\n",
      "iter: 46000, p: 0, loss: 0.851562\n",
      "----\n",
      " Zock  \n",
      "----\n",
      "\n",
      "iter: 47000, p: 0, loss: 0.831618\n",
      "----\n",
      " Electric  \n",
      "----\n",
      "\n",
      "iter: 48000, p: 0, loss: 0.459734\n",
      "----\n",
      " Agsoock Bug  \n",
      "----\n",
      "\n",
      "iter: 49000, p: 0, loss: 0.481592\n",
      "----\n",
      " Forme Ghost  \n",
      "----\n",
      "\n",
      "iter: 50000, p: 0, loss: 1.202878\n",
      "----\n",
      " X Fire  \n",
      "----\n",
      "\n",
      "iter: 51000, p: 0, loss: 0.572951\n",
      "----\n",
      " Cluplubbumerird Electric  \n",
      "----\n",
      "\n",
      "iter: 52000, p: 0, loss: 0.776705\n",
      "----\n",
      " Sazak Water  \n",
      "----\n",
      "\n",
      "iter: 53000, p: 0, loss: 0.712843\n",
      "----\n",
      " Clerrow Norme Psychic  \n",
      "----\n",
      "\n",
      "iter: 54000, p: 0, loss: 0.974382\n",
      "----\n",
      " Y Ground  \n",
      "----\n",
      "\n",
      "iter: 55000, p: 0, loss: 1.276438\n",
      "----\n",
      " Bug  \n",
      "----\n",
      "\n",
      "iter: 56000, p: 0, loss: 0.333736\n",
      "----\n",
      " Psychic  \n",
      "----\n",
      "\n",
      "iter: 57000, p: 0, loss: 0.728384\n",
      "----\n",
      " Forme Groudo Normal  \n",
      "----\n",
      "\n",
      "iter: 58000, p: 0, loss: 0.495471\n",
      "----\n",
      " Qne Water  \n",
      "----\n",
      "\n",
      "iter: 59000, p: 0, loss: 1.190648\n",
      "----\n",
      " Condout Fairy  \n",
      "----\n",
      "\n",
      "iter: 60000, p: 0, loss: 0.617496\n",
      "----\n",
      " Normal  \n",
      "----\n",
      "\n",
      "iter: 61000, p: 0, loss: 0.659755\n",
      "----\n",
      " Zock  \n",
      "----\n",
      "\n",
      "iter: 62000, p: 0, loss: 0.450621\n",
      "----\n",
      " Forme Water  \n",
      "----\n",
      "\n",
      "iter: 63000, p: 0, loss: 0.628102\n",
      "----\n",
      " Cotombre Electric  \n",
      "----\n",
      "\n",
      "iter: 64000, p: 0, loss: 0.514642\n",
      "----\n",
      " Laire  \n",
      "----\n",
      "\n",
      "iter: 65000, p: 0, loss: 1.069899\n",
      "----\n",
      " Qorme Bug  \n",
      "----\n",
      "\n",
      "iter: 66000, p: 0, loss: 0.336504\n",
      "----\n",
      " Alectredachyross Electric  \n",
      "----\n",
      "\n",
      "iter: 67000, p: 0, loss: 0.730779\n",
      "----\n",
      " Poison  \n",
      "----\n",
      "\n",
      "iter: 68000, p: 0, loss: 0.442274\n",
      "----\n",
      " Shass Electric  \n",
      "----\n",
      "\n",
      "iter: 69000, p: 0, loss: 0.628389\n",
      "----\n",
      " Size Normal  \n",
      "----\n",
      "\n",
      "iter: 70000, p: 0, loss: 0.887535\n",
      "----\n",
      " Lorm Electric Electric  \n",
      "----\n",
      "\n",
      "iter: 71000, p: 0, loss: 0.964548\n",
      "----\n",
      " Ane Grass  \n",
      "----\n",
      "\n",
      "iter: 72000, p: 0, loss: 0.932668\n",
      "----\n",
      " Electric  \n",
      "----\n",
      "\n",
      "iter: 73000, p: 0, loss: 0.513384\n",
      "----\n",
      " Jormal  \n",
      "----\n",
      "\n",
      "iter: 74000, p: 0, loss: 1.114609\n",
      "----\n",
      " Z \n",
      "----\n",
      "\n",
      "iter: 75000, p: 0, loss: 0.639089\n",
      "----\n",
      " Ice  \n",
      "----\n",
      "\n",
      "iter: 76000, p: 0, loss: 0.460273\n",
      "----\n",
      " X Poison  \n",
      "----\n",
      "\n",
      "iter: 77000, p: 0, loss: 1.286756\n",
      "----\n",
      " Zufffaye Dragon  \n",
      "----\n",
      "\n",
      "iter: 78000, p: 0, loss: 0.749277\n",
      "----\n",
      " Dragon  \n",
      "----\n",
      "\n",
      "iter: 79000, p: 0, loss: 0.820914\n",
      "----\n",
      " Dark  \n",
      "----\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0d99eda8848c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                         feed_dict={inputs: np.asarray(input_vals[c]).reshape(1,1),\n\u001b[1;32m     37\u001b[0m                                                    \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                                    init_state: h_t})\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/florian/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/florian/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/florian/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/florian/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/florian/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/florian/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# now that all the functions are set up we can run this thing\n",
    "\n",
    "# function to one hot encode the characters\n",
    "def one_hot(v):\n",
    "    return np.eye(vocab_size)[v]\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Initial values\n",
    "n, p = 0, 0\n",
    "#hprev_val = np.zeros([1, hidden_size])\n",
    "\n",
    "for _ in range(epochs):\n",
    "    pokemons = shuffle(pokemons)\n",
    "    for pokemon in pokemons:\n",
    "\n",
    "        # Initialize the hidden state to 0 at the beginning of each sequence\n",
    "        h_t = np.zeros([1, hidden_size])\n",
    "\n",
    "        # Prepare inputs\n",
    "        input_vals, target_vals = list_iter(pokemon)\n",
    "\n",
    "        input_vals = [char2idx[c] for c in input_vals]\n",
    "        target_vals = [char2idx[c] for c in target_vals]\n",
    "\n",
    "        #input_vals  = one_hot(input_vals)\n",
    "        target_vals = one_hot(target_vals)\n",
    "\n",
    "        losses = []\n",
    "        for c in range(len(input_vals)):\n",
    "            # run the tensorflow session\n",
    "            h_t, loss_val, _ = sess.run([h_0, loss, updates],\n",
    "                                        feed_dict={inputs: np.asarray(input_vals[c]).reshape(1,1),\n",
    "                                                   targets: target_vals[c].reshape(1,100),\n",
    "                                                   init_state: h_t})\n",
    "            losses.append(loss_val)\n",
    "    \n",
    "        if n % 1000 == 0:\n",
    "            # Progress\n",
    "            print('iter: %d, p: %d, loss: %f' % (n, p, np.mean(losses)))\n",
    "\n",
    "            # Do sampling\n",
    "            sample_length = 50\n",
    "            prime_str_idx = np.random.randint(len(string.ascii_uppercase))\n",
    "            prime_str = string.ascii_uppercase[prime_str_idx]\n",
    "\n",
    "            idxs = []\n",
    "            sample_prev_state_val = np.copy(h_t)\n",
    "            sample_input_vals = np.asarray([char2idx[prime_str]]).reshape(1,1)\n",
    "\n",
    "            for t in range(sample_length):\n",
    "                sample_output_softmax_val, sample_prev_state_val = \\\n",
    "                    sess.run([output_softmax, h_0],\n",
    "                             feed_dict={inputs: sample_input_vals, init_state: sample_prev_state_val})\n",
    "\n",
    "                predicted_idx = (np.argmax(sample_output_softmax_val))\n",
    "\n",
    "                idxs.append(predicted_idx)\n",
    "                sample_input_vals = np.asarray([predicted_idx]).reshape(1,1)\n",
    "\n",
    "            txt = prime_str + ''.join(idx2char[ix] for ix in idxs)\n",
    "            print('----\\n %s \\n----\\n' % (txt.split('|')[0],))\n",
    "\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
