{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Tensorflow\n",
    "\n",
    "Tensorflow is a framework for defining and running computational graphs. It's primarily used for deep learning although it can also be used for other numerical computing and machine learning tasks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Graphs and Sessions\n",
    "\n",
    "Tensorflow uses computational graphs to run it's functions and models. Graphs are defined by their operations and variables.\n",
    "\n",
    "Sessions are used to run the a graph. They create the connection between the python program and the C++ TF runtime. Setting up the graph, variables and operations can be done outside the session. But, nothing will be run until it's connected to the session and we evaluate the expression that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Output: 66240\n",
      "Python Output: 66240\n"
     ]
    }
   ],
   "source": [
    "# set up two variables\n",
    "x = tf.Variable(32, name='x')\n",
    "y = tf.Variable(45, name='y')\n",
    "\n",
    "# set up some expression to perform on these variables\n",
    "f = x*y + y*x*y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print('Tensorflow Output:', result)\n",
    "    \n",
    "print('Python Output:', 32*45 + 45*32*45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: \n",
    "\n",
    "Use placeholders to create a system that can add any two numbers. Since we will primarily be doing machine learning with TensorFlow we don't necessarily want the data in our graph at the start. We want to have buckets that we can put data into and get some result. Set up the same system as above except this time using placeholders so that we can pass values into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66240]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int32, shape=(1,), name='x_phldr')\n",
    "y = tf.placeholder(tf.int32, shape=(1,), name='y_phldr')\n",
    "z = x*y + y*x*y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(z, feed_dict={x:[32], y:[45]})\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Linear Regression in Tensorflow\n",
    "\n",
    "Running a basic linear regreesion in Tensorflow with built in optimizers and gradient descent algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the california housing dataset, view the shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "# load the data into numpy arrays\n",
    "housing_features = housing.data\n",
    "housing_targets = housing.target\n",
    "\n",
    "n, f_dim = housing_features.shape\n",
    "\n",
    "# normalize the features\n",
    "housing_features= normalize(housing_features)\n",
    "\n",
    "# add bias\n",
    "housing_features = np.c_[np.ones((n, 1)), housing_features]\n",
    "\n",
    "housing_features = housing_features[housing_targets < 5]\n",
    "housing_targets = housing_targets[housing_targets < 5]\n",
    "\n",
    "# reshape targets to TF expectation\n",
    "housing_targets = np.expand_dims(housing_targets, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_features,\n",
    "                                                    housing_targets,\n",
    "                                                    test_size=0.1)\n",
    "\n",
    "print(housing.feature_names)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR = 0.005\n",
    "EPOCHS = 5000\n",
    "# save all of the losses\n",
    "losses = []\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, f_dim+1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "W = tf.Variable(tf.ones([f_dim+1, 1]))\n",
    "\n",
    "# after launching a session, run the initializer to initialize all of\n",
    "# the variables in the graph\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# set up operation to get the output from the regression, \n",
    "# dot product of weight  and features\n",
    "y_pred = tf.matmul(X, W)\n",
    "\n",
    "# calculate the mean squared error\n",
    "error = y_pred - y\n",
    "loss = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "# use TF's built in autograd features to run gradient descent\n",
    "train_step = tf.train.GradientDescentOptimizer(LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        if e % 100 == 0:\n",
    "            print(\"Epoch:\", e, \n",
    "                  \"Current loss:\", \n",
    "                  sess.run(loss, feed_dict={X: X_train, y: y_train}), \n",
    "                  \"Test loss:\",\n",
    "                 sess.run(loss, feed_dict={X: X_test, y: y_test}))\n",
    "            \n",
    "        sess.run(train_step, feed_dict={X: X_train, y: y_train})\n",
    "        losses.append(sess.run(loss, feed_dict={X: X_train, y: y_train}))\n",
    "        \n",
    "    best_weights = W.eval()\n",
    "    save_path = saver.save(sess, '/tmp/linear_regression.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses)),np.array(losses))\n",
    "plt.axis([0,EPOCHS,np.min(losses),np.max(losses)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "### Making predictions on our test data\n",
    "\n",
    "Now that we have our trained model, we can load it up and make predictions on our test set. Load the model from the stored state, and run the prediction function with a TensorFlow Session on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# best weight values are saved in the checkpoint\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '/tmp/linear_regression.ckpt')\n",
    "    preds = sess.run(y_pred, feed_dict={X: X_test})\n",
    "    print(sess.run(loss, feed_dict={X: X_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, preds)\n",
    "ax.plot([y_test.min(), y_test.max()], \n",
    "        [y_test.min(), y_test.max()], '--', lw=3, color='r')\n",
    "ax.set_xlabel('True Value')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
