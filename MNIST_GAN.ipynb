{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the small MNIST dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNyyRs2/TGgiSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131a3c860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load the digits dataset\n",
    "digits = datasets.load_digits().data\n",
    "\n",
    "# scale between 0 and 1\n",
    "digits = digits / np.max(digits)\n",
    "\n",
    "# reshape the data so that each example is an image\n",
    "n = digits.shape[0]\n",
    "digits = digits.reshape(n, 8, 8)\n",
    "\n",
    "# display an image\n",
    "plt.imshow(digits[0], cmap=plt.cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import what we need from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be following the [DCGAN](https://arxiv.org/abs/1511.06434) methodology here. In which both the discriminator and generator are convolutional neural networks. The generator will use a random vector as a seed to build the images from. Using a random vector will cause us to have variability in the generated images.\n",
    "\n",
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DCGAN_Generator(nn.Module):\n",
    "    def __init__(self, featmap_dim=256, n_channel=3, noise_dim=100):\n",
    "        super(DCGAN_Generator, self).__init__()\n",
    "        self.featmap_dim = featmap_dim\n",
    "        self.fc1 = nn.Linear(100, 4 * 4 * featmap_dim)\n",
    "        self.conv1 = nn.ConvTranspose2d(featmap_dim, 64, kernel_size=2,\n",
    "                                        stride=1, padding=0, bias=False)\n",
    "        self.BN1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose2d(64, 32, kernel_size=2,\n",
    "                                        stride=1, padding=0, bias=False)\n",
    "        self.BN2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.ConvTranspose2d(32, 16, kernel_size=2,\n",
    "                                        stride=1, padding=0, bias=False)\n",
    "        self.BN3 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv4 = nn.ConvTranspose2d(16, n_channel, kernel_size=2,\n",
    "                                        stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Project noise to featureMap * width * height,\n",
    "        Batch Normalization after convulation but not at output layer,\n",
    "        ReLU activation function.\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1, self.featmap_dim, 4, 4)\n",
    "        x = F.relu(self.BN1(self.conv1(x)))\n",
    "        x = F.relu(self.BN2(self.conv2(x)))\n",
    "        x = F.relu(self.BN3(self.conv3(x)))\n",
    "        x = F.sigmoid(self.conv4(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # input is 1 x 8 x 8\n",
    "            nn.Conv2d(1, 32, 3, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 32 x 4 x 4\n",
    "            nn.Conv2d(32, 64, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.features(input)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        #print(output.size())\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch data loaders\n",
    "\n",
    "PyTorch includes some tools to automatically crate data loaders to effeciently stream data into the networks. We'll set one up with the numpy array that contains our MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797, 1, 8, 8])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_tch = torch.from_numpy(digits).unsqueeze(1).float()\n",
    "digits_tch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# wrap the digits torch tensor in a TensorDataset\n",
    "# requires labels, remember all real data is label 1\n",
    "targets = torch.ones(digits_tch.size(0)).unsqueeze(1).float()\n",
    "digits_train = data.TensorDataset(data_tensor=digits_tch, \n",
    "                                  target_tensor=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to wrap this dataset into a dataloader for efficient processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(digits_train,\n",
    "                               batch_size=16,\n",
    "                               shuffle=True,\n",
    "                               num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the networks, optimizers and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = Discriminator()\n",
    "G = DCGAN_Generator(featmap_dim=128, n_channel=1, noise_dim=25)\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up the noise\n",
    "noise = torch.FloatTensor(16, 100)\n",
    "fixed_noise = torch.FloatTensor(16, 100).normal_(0,1)\n",
    "\n",
    "def train(epoch):\n",
    "    # keep track of accuracy\n",
    "    total_r = 0\n",
    "    total_f = 0\n",
    "    correct_r = 0\n",
    "    # keep track of losses\n",
    "    iter_r_loss = 0.\n",
    "    iter_r_correct = 0.\n",
    "    iter_f_loss = 0.\n",
    "    iter_f_correct = 0.\n",
    "    num_batch_epoch = 0\n",
    "    # keep track of acc\n",
    "    total_g = 0\n",
    "    correct_g = 0\n",
    "    # keep track of loss\n",
    "    iter_g_loss = 0.\n",
    "    iter_g_correct = 0.\n",
    "    num_batch_epoch = 0.\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #################################################\n",
    "        # Train with Real and test on fake, update D net\n",
    "        #################################################\n",
    "\n",
    "        # get the inputs\n",
    "        inputs, true_labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs)\n",
    "        true_labels = Variable(true_labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = D(inputs)\n",
    "        #print(outputs.data)\n",
    "        loss_r = criterion(outputs, true_labels)\n",
    "        loss_r.backward()\n",
    "        D_x = outputs.data.mean()\n",
    "\n",
    "        # check accuracy of real data\n",
    "        predicted = torch.round(outputs.data)\n",
    "        total_r += true_labels.size(0)\n",
    "        iter_r_correct += predicted.eq(true_labels.data).sum()\n",
    "\n",
    "        iter_r_loss += loss_r.data[0]\n",
    "\n",
    "        # get fake labels\n",
    "        fake_labels = Variable(torch.zeros(16))\n",
    "        # get uniform distribution to prime generator\n",
    "        noisev = Variable(noise.normal_(0,1))\n",
    "        # generate fake airplane images\n",
    "        fake_data = G(noisev)\n",
    "        # predict whether or not the airplane images were real\n",
    "        fake_out = D(fake_data.detach())\n",
    "        #print(fake_out.data)\n",
    "        # calculate loss\n",
    "        loss_f = criterion(fake_out, fake_labels)\n",
    "        # do backwards pass\n",
    "        loss_f.backward()\n",
    "\n",
    "        # check accuracy of the fake data\n",
    "        predicted = torch.round(fake_out.data)\n",
    "        total_f += fake_labels.size(0)\n",
    "        iter_f_correct += predicted.eq(fake_labels.data).cpu().sum()\n",
    "\n",
    "        iter_f_loss += loss_f.data[0]\n",
    "\n",
    "        # update those grads!\n",
    "        D_G_z1 = fake_out.data.mean()\n",
    "        loss = loss_r + loss_f\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "        #################################################\n",
    "        # Train with Fake, update G net\n",
    "        #################################################\n",
    "\n",
    "        # get labels\n",
    "        g_optimizer.zero_grad()\n",
    "        gen_labels = Variable(torch.ones(16)) # ones this time since we want the generator to get better\n",
    "        # see what D thinks\n",
    "        gen_out = D(fake_data)\n",
    "        #print(gen_out.data)\n",
    "        # get loss\n",
    "        g_loss = criterion(gen_out, gen_labels)\n",
    "        # do the backwards pass\n",
    "        g_loss.backward()\n",
    "\n",
    "        # check accuracy of the fake data\n",
    "        predicted = torch.round(gen_out.data)\n",
    "        total_g += gen_labels.size(0)\n",
    "        iter_g_correct += predicted.eq(gen_labels.data).sum()\n",
    "\n",
    "        iter_g_loss += g_loss.data[0]\n",
    "\n",
    "        # update weights of generator\n",
    "        g_optimizer.step()\n",
    "\n",
    "        num_batch_epoch += 1\n",
    "\n",
    "    print('\\nTrain Real Loss: {:.3} | Train Real Acc: {:.3}'.format(iter_r_loss / num_batch_epoch, \n",
    "            float(iter_r_correct) / (num_batch_epoch*16)))\n",
    "\n",
    "    print('Train Fake Loss: {:.3} | Train Fake Acc: {:.3}'.format(iter_f_loss / num_batch_epoch, \n",
    "            float(iter_f_correct) / (num_batch_epoch*16)))\n",
    "\n",
    "    print('GAN Loss: {:.3} | GAN Acc: {:.3}'.format(iter_g_loss / num_batch_epoch, \n",
    "        float(iter_g_correct) / (num_batch_epoch*16)))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        vutils.save_image(fake_data.data, 'images/GAN_imgs/generated_digits_' + str(epoch) + '.png', normalize=True)\n",
    "\n",
    "    return iter_r_loss / num_batch_epoch, iter_f_loss / num_batch_epoch, iter_g_loss / num_batch_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "\n",
      "Epoch 0/50\n",
      "\n",
      "Train Real Loss: 0.115 | Train Real Acc: 0.985\n",
      "Train Fake Loss: 0.104 | Train Fake Acc: 0.992\n",
      "GAN Loss: 2.75 | GAN Acc: 0.0\n",
      "Time: 3.129142999649048\n",
      "\n",
      "Epoch 1/50\n",
      "\n",
      "Train Real Loss: 0.0216 | Train Real Acc: 0.994\n",
      "Train Fake Loss: 0.0231 | Train Fake Acc: 1.0\n",
      "GAN Loss: 4.11 | GAN Acc: 0.0\n",
      "Time: 3.1301209926605225\n",
      "\n",
      "Epoch 2/50\n",
      "\n",
      "Train Real Loss: 0.0187 | Train Real Acc: 0.994\n",
      "Train Fake Loss: 0.0214 | Train Fake Acc: 0.999\n",
      "GAN Loss: 4.5 | GAN Acc: 0.0\n",
      "Time: 3.163874864578247\n",
      "\n",
      "Epoch 3/50\n",
      "\n",
      "Train Real Loss: 0.143 | Train Real Acc: 0.944\n",
      "Train Fake Loss: 0.143 | Train Fake Acc: 0.956\n",
      "GAN Loss: 3.38 | GAN Acc: 0.0194\n",
      "Time: 3.417105197906494\n",
      "\n",
      "Epoch 4/50\n",
      "\n",
      "Train Real Loss: 0.285 | Train Real Acc: 0.881\n",
      "Train Fake Loss: 0.303 | Train Fake Acc: 0.881\n",
      "GAN Loss: 2.57 | GAN Acc: 0.0774\n",
      "Time: 3.334590196609497\n",
      "\n",
      "Epoch 5/50\n",
      "\n",
      "Train Real Loss: 0.308 | Train Real Acc: 0.87\n",
      "Train Fake Loss: 0.301 | Train Fake Acc: 0.872\n",
      "GAN Loss: 2.39 | GAN Acc: 0.0785\n",
      "Time: 3.3093628883361816\n",
      "\n",
      "Epoch 6/50\n",
      "\n",
      "Train Real Loss: 0.401 | Train Real Acc: 0.811\n",
      "Train Fake Loss: 0.346 | Train Fake Acc: 0.868\n",
      "GAN Loss: 1.9 | GAN Acc: 0.0946\n",
      "Time: 3.3309600353240967\n",
      "\n",
      "Epoch 7/50\n",
      "\n",
      "Train Real Loss: 0.434 | Train Real Acc: 0.797\n",
      "Train Fake Loss: 0.418 | Train Fake Acc: 0.826\n",
      "GAN Loss: 1.68 | GAN Acc: 0.129\n",
      "Time: 3.544092893600464\n",
      "\n",
      "Epoch 8/50\n",
      "\n",
      "Train Real Loss: 0.412 | Train Real Acc: 0.803\n",
      "Train Fake Loss: 0.407 | Train Fake Acc: 0.832\n",
      "GAN Loss: 1.67 | GAN Acc: 0.134\n",
      "Time: 3.4585821628570557\n",
      "\n",
      "Epoch 9/50\n",
      "\n",
      "Train Real Loss: 0.519 | Train Real Acc: 0.741\n",
      "Train Fake Loss: 0.471 | Train Fake Acc: 0.79\n",
      "GAN Loss: 1.51 | GAN Acc: 0.169\n",
      "Time: 3.3822319507598877\n",
      "\n",
      "Epoch 10/50\n",
      "\n",
      "Train Real Loss: 0.488 | Train Real Acc: 0.755\n",
      "Train Fake Loss: 0.459 | Train Fake Acc: 0.818\n",
      "GAN Loss: 1.39 | GAN Acc: 0.15\n",
      "Time: 3.4073050022125244\n",
      "\n",
      "Epoch 11/50\n",
      "\n",
      "Train Real Loss: 0.523 | Train Real Acc: 0.722\n",
      "Train Fake Loss: 0.497 | Train Fake Acc: 0.8\n",
      "GAN Loss: 1.19 | GAN Acc: 0.175\n",
      "Time: 3.463809013366699\n",
      "\n",
      "Epoch 12/50\n",
      "\n",
      "Train Real Loss: 0.576 | Train Real Acc: 0.679\n",
      "Train Fake Loss: 0.542 | Train Fake Acc: 0.728\n",
      "GAN Loss: 1.23 | GAN Acc: 0.23\n",
      "Time: 3.4447550773620605\n",
      "\n",
      "Epoch 13/50\n",
      "\n",
      "Train Real Loss: 0.534 | Train Real Acc: 0.723\n",
      "Train Fake Loss: 0.517 | Train Fake Acc: 0.77\n",
      "GAN Loss: 1.13 | GAN Acc: 0.204\n",
      "Time: 3.452265977859497\n",
      "\n",
      "Epoch 14/50\n",
      "\n",
      "Train Real Loss: 0.508 | Train Real Acc: 0.741\n",
      "Train Fake Loss: 0.509 | Train Fake Acc: 0.759\n",
      "GAN Loss: 1.2 | GAN Acc: 0.2\n",
      "Time: 3.4399170875549316\n",
      "\n",
      "Epoch 15/50\n",
      "\n",
      "Train Real Loss: 0.495 | Train Real Acc: 0.76\n",
      "Train Fake Loss: 0.476 | Train Fake Acc: 0.804\n",
      "GAN Loss: 1.26 | GAN Acc: 0.165\n",
      "Time: 3.4378609657287598\n",
      "\n",
      "Epoch 16/50\n",
      "\n",
      "Train Real Loss: 0.496 | Train Real Acc: 0.754\n",
      "Train Fake Loss: 0.509 | Train Fake Acc: 0.776\n",
      "GAN Loss: 1.26 | GAN Acc: 0.18\n",
      "Time: 3.5270111560821533\n",
      "\n",
      "Epoch 17/50\n",
      "\n",
      "Train Real Loss: 0.521 | Train Real Acc: 0.732\n",
      "Train Fake Loss: 0.509 | Train Fake Acc: 0.764\n",
      "GAN Loss: 1.29 | GAN Acc: 0.188\n",
      "Time: 3.5485849380493164\n",
      "\n",
      "Epoch 18/50\n",
      "\n",
      "Train Real Loss: 0.473 | Train Real Acc: 0.78\n",
      "Train Fake Loss: 0.456 | Train Fake Acc: 0.802\n",
      "GAN Loss: 1.42 | GAN Acc: 0.163\n",
      "Time: 3.4455201625823975\n",
      "\n",
      "Epoch 19/50\n",
      "\n",
      "Train Real Loss: 0.503 | Train Real Acc: 0.756\n",
      "Train Fake Loss: 0.497 | Train Fake Acc: 0.783\n",
      "GAN Loss: 1.27 | GAN Acc: 0.176\n",
      "Time: 3.454969882965088\n",
      "\n",
      "Epoch 20/50\n",
      "\n",
      "Train Real Loss: 0.47 | Train Real Acc: 0.772\n",
      "Train Fake Loss: 0.431 | Train Fake Acc: 0.824\n",
      "GAN Loss: 1.5 | GAN Acc: 0.135\n",
      "Time: 3.592895030975342\n",
      "\n",
      "Epoch 21/50\n",
      "\n",
      "Train Real Loss: 0.433 | Train Real Acc: 0.815\n",
      "Train Fake Loss: 0.453 | Train Fake Acc: 0.799\n",
      "GAN Loss: 1.5 | GAN Acc: 0.161\n",
      "Time: 3.625047206878662\n",
      "\n",
      "Epoch 22/50\n",
      "\n",
      "Train Real Loss: 0.489 | Train Real Acc: 0.765\n",
      "Train Fake Loss: 0.445 | Train Fake Acc: 0.808\n",
      "GAN Loss: 1.43 | GAN Acc: 0.155\n",
      "Time: 3.652729034423828\n",
      "\n",
      "Epoch 23/50\n",
      "\n",
      "Train Real Loss: 0.451 | Train Real Acc: 0.801\n",
      "Train Fake Loss: 0.439 | Train Fake Acc: 0.809\n",
      "GAN Loss: 1.48 | GAN Acc: 0.147\n",
      "Time: 3.4806199073791504\n",
      "\n",
      "Epoch 24/50\n",
      "\n",
      "Train Real Loss: 0.406 | Train Real Acc: 0.824\n",
      "Train Fake Loss: 0.375 | Train Fake Acc: 0.867\n",
      "GAN Loss: 1.59 | GAN Acc: 0.1\n",
      "Time: 3.4772751331329346\n",
      "\n",
      "Epoch 25/50\n",
      "\n",
      "Train Real Loss: 0.391 | Train Real Acc: 0.835\n",
      "Train Fake Loss: 0.378 | Train Fake Acc: 0.857\n",
      "GAN Loss: 1.66 | GAN Acc: 0.106\n",
      "Time: 3.4351119995117188\n",
      "\n",
      "Epoch 26/50\n",
      "\n",
      "Train Real Loss: 0.386 | Train Real Acc: 0.845\n",
      "Train Fake Loss: 0.385 | Train Fake Acc: 0.852\n",
      "GAN Loss: 1.63 | GAN Acc: 0.104\n",
      "Time: 3.376573085784912\n",
      "\n",
      "Epoch 27/50\n",
      "\n",
      "Train Real Loss: 0.395 | Train Real Acc: 0.817\n",
      "Train Fake Loss: 0.358 | Train Fake Acc: 0.86\n",
      "GAN Loss: 1.73 | GAN Acc: 0.0935\n",
      "Time: 3.4412429332733154\n",
      "\n",
      "Epoch 28/50\n",
      "\n",
      "Train Real Loss: 0.373 | Train Real Acc: 0.831\n",
      "Train Fake Loss: 0.357 | Train Fake Acc: 0.863\n",
      "GAN Loss: 1.75 | GAN Acc: 0.105\n",
      "Time: 3.4548778533935547\n",
      "\n",
      "Epoch 29/50\n",
      "\n",
      "Train Real Loss: 0.378 | Train Real Acc: 0.836\n",
      "Train Fake Loss: 0.375 | Train Fake Acc: 0.853\n",
      "GAN Loss: 1.74 | GAN Acc: 0.101\n",
      "Time: 3.4352800846099854\n",
      "\n",
      "Epoch 30/50\n",
      "\n",
      "Train Real Loss: 0.384 | Train Real Acc: 0.83\n",
      "Train Fake Loss: 0.365 | Train Fake Acc: 0.851\n",
      "GAN Loss: 1.78 | GAN Acc: 0.103\n",
      "Time: 3.3723599910736084\n",
      "\n",
      "Epoch 31/50\n",
      "\n",
      "Train Real Loss: 0.33 | Train Real Acc: 0.881\n",
      "Train Fake Loss: 0.307 | Train Fake Acc: 0.91\n",
      "GAN Loss: 1.83 | GAN Acc: 0.0625\n",
      "Time: 3.4603350162506104\n",
      "\n",
      "Epoch 32/50\n",
      "\n",
      "Train Real Loss: 0.383 | Train Real Acc: 0.836\n",
      "Train Fake Loss: 0.376 | Train Fake Acc: 0.852\n",
      "GAN Loss: 1.69 | GAN Acc: 0.114\n",
      "Time: 3.402971029281616\n",
      "\n",
      "Epoch 33/50\n",
      "\n",
      "Train Real Loss: 0.378 | Train Real Acc: 0.842\n",
      "Train Fake Loss: 0.357 | Train Fake Acc: 0.863\n",
      "GAN Loss: 1.75 | GAN Acc: 0.0951\n",
      "Time: 3.412548780441284\n",
      "\n",
      "Epoch 34/50\n",
      "\n",
      "Train Real Loss: 0.38 | Train Real Acc: 0.855\n",
      "Train Fake Loss: 0.394 | Train Fake Acc: 0.842\n",
      "GAN Loss: 1.62 | GAN Acc: 0.123\n",
      "Time: 3.453766107559204\n",
      "\n",
      "Epoch 35/50\n",
      "\n",
      "Train Real Loss: 0.369 | Train Real Acc: 0.856\n",
      "Train Fake Loss: 0.343 | Train Fake Acc: 0.883\n",
      "GAN Loss: 1.7 | GAN Acc: 0.0874\n",
      "Time: 3.390292167663574\n",
      "\n",
      "Epoch 36/50\n",
      "\n",
      "Train Real Loss: 0.358 | Train Real Acc: 0.861\n",
      "Train Fake Loss: 0.369 | Train Fake Acc: 0.85\n",
      "GAN Loss: 1.75 | GAN Acc: 0.105\n",
      "Time: 3.3914170265197754\n",
      "\n",
      "Epoch 37/50\n",
      "\n",
      "Train Real Loss: 0.354 | Train Real Acc: 0.852\n",
      "Train Fake Loss: 0.338 | Train Fake Acc: 0.877\n",
      "GAN Loss: 1.79 | GAN Acc: 0.089\n",
      "Time: 3.4814159870147705\n",
      "\n",
      "Epoch 38/50\n",
      "\n",
      "Train Real Loss: 0.34 | Train Real Acc: 0.858\n",
      "Train Fake Loss: 0.333 | Train Fake Acc: 0.864\n",
      "GAN Loss: 1.89 | GAN Acc: 0.0968\n",
      "Time: 3.41599702835083\n",
      "\n",
      "Epoch 39/50\n",
      "\n",
      "Train Real Loss: 0.33 | Train Real Acc: 0.87\n",
      "Train Fake Loss: 0.328 | Train Fake Acc: 0.887\n",
      "GAN Loss: 1.88 | GAN Acc: 0.0874\n",
      "Time: 3.408137083053589\n",
      "\n",
      "Epoch 40/50\n",
      "\n",
      "Train Real Loss: 0.354 | Train Real Acc: 0.855\n",
      "Train Fake Loss: 0.337 | Train Fake Acc: 0.873\n",
      "GAN Loss: 1.81 | GAN Acc: 0.0968\n",
      "Time: 3.4602110385894775\n",
      "\n",
      "Epoch 41/50\n",
      "\n",
      "Train Real Loss: 0.349 | Train Real Acc: 0.845\n",
      "Train Fake Loss: 0.36 | Train Fake Acc: 0.858\n",
      "GAN Loss: 1.77 | GAN Acc: 0.104\n",
      "Time: 3.5416460037231445\n",
      "\n",
      "Epoch 42/50\n",
      "\n",
      "Train Real Loss: 0.378 | Train Real Acc: 0.835\n",
      "Train Fake Loss: 0.374 | Train Fake Acc: 0.86\n",
      "GAN Loss: 1.76 | GAN Acc: 0.117\n",
      "Time: 3.4585671424865723\n",
      "\n",
      "Epoch 43/50\n",
      "\n",
      "Train Real Loss: 0.344 | Train Real Acc: 0.861\n",
      "Train Fake Loss: 0.343 | Train Fake Acc: 0.865\n",
      "GAN Loss: 1.79 | GAN Acc: 0.0985\n",
      "Time: 3.5577518939971924\n",
      "\n",
      "Epoch 44/50\n",
      "\n",
      "Train Real Loss: 0.361 | Train Real Acc: 0.861\n",
      "Train Fake Loss: 0.344 | Train Fake Acc: 0.867\n",
      "GAN Loss: 1.77 | GAN Acc: 0.0929\n",
      "Time: 3.491546154022217\n",
      "\n",
      "Epoch 45/50\n",
      "\n",
      "Train Real Loss: 0.381 | Train Real Acc: 0.829\n",
      "Train Fake Loss: 0.375 | Train Fake Acc: 0.838\n",
      "GAN Loss: 1.8 | GAN Acc: 0.116\n",
      "Time: 3.4692790508270264\n",
      "\n",
      "Epoch 46/50\n",
      "\n",
      "Train Real Loss: 0.362 | Train Real Acc: 0.851\n",
      "Train Fake Loss: 0.348 | Train Fake Acc: 0.872\n",
      "GAN Loss: 1.77 | GAN Acc: 0.0907\n",
      "Time: 3.4338159561157227\n",
      "\n",
      "Epoch 47/50\n",
      "\n",
      "Train Real Loss: 0.36 | Train Real Acc: 0.871\n",
      "Train Fake Loss: 0.386 | Train Fake Acc: 0.842\n",
      "GAN Loss: 1.65 | GAN Acc: 0.119\n",
      "Time: 3.7301621437072754\n",
      "\n",
      "Epoch 48/50\n",
      "\n",
      "Train Real Loss: 0.305 | Train Real Acc: 0.89\n",
      "Train Fake Loss: 0.304 | Train Fake Acc: 0.888\n",
      "GAN Loss: 1.97 | GAN Acc: 0.0747\n",
      "Time: 3.7783470153808594\n",
      "\n",
      "Epoch 49/50\n",
      "\n",
      "Train Real Loss: 0.327 | Train Real Acc: 0.858\n",
      "Train Fake Loss: 0.337 | Train Fake Acc: 0.875\n",
      "GAN Loss: 1.96 | GAN Acc: 0.0929\n",
      "Time: 3.8090500831604004\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "lr_patience = 0\n",
    "best_gan_loss = 20.\n",
    "try:\n",
    "    print('Training ...')\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    for e in range(50):  # loop over the dataset multiple times\n",
    "        print('\\n' + 'Epoch {}/{}'.format(e, 50))\n",
    "        start = time.time()\n",
    "\n",
    "        trl, tfl, tgl = train(e)\n",
    "\n",
    "        # save the model everytime we get a new best valid loss\n",
    "        if tgl < best_gan_loss:\n",
    "            torch.save(G.state_dict(), 'models/digit_gan.pth')\n",
    "            best_gan_loss = tgl\n",
    "\n",
    "        print('Time: {}'.format(time.time()-start))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Init\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB8CAYAAAB5R0uKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131b3a668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 30 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB8CAYAAAB5R0uKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJCbQoRNCSEygQyeEkJhAh04IITHh/wFllL9YUrbCgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130bdeba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "print('Random Init')\n",
    "plt.imshow(mpimg.imread('images/GAN_imgs/generated_digits_0.png'))\n",
    "plt.show()\n",
    "\n",
    "print('After 30 iterations')\n",
    "plt.imshow(mpimg.imread('images/GAN_imgs/generated_digits_30.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
